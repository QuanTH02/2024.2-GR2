#!/usr/bin/env python3
"""
Script ph√¢n t√≠ch chi ti·∫øt c√°c l·ªói logic trong k·∫øt qu·∫£ JSON
v√† ƒë∆∞a ra gi·∫£i ph√°p kh·∫Øc ph·ª•c
"""

import json
import os
from typing import Dict, List, Any

def detailed_logic_analysis(file_path: str) -> Dict[str, Any]:
    """Ph√¢n t√≠ch chi ti·∫øt logic v√† ƒë∆∞a ra gi·∫£i ph√°p"""
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    analysis = {
        'total_samples': len(data),
        'critical_errors': [],
        'logic_issues': [],
        'data_quality_issues': [],
        'recommendations': []
    }
    
    # Ph√¢n t√≠ch t·ª´ng sample
    for i, sample in enumerate(data):
        sample_issues = []
        
        # 1. Ph√¢n t√≠ch field 'success'
        success = sample.get('success', -1)
        pred_bleu = sample.get('pred_bleu', 0)
        after_attack_bleu = sample.get('after_attack_bleu', 0)
        change = sample.get('change', 0)
        query = sample.get('query', 0)
        changes = sample.get('changes', [])
        gold_out = sample.get('gold_out', '').strip()
        input_text = sample.get('input', '').strip()
        adv_text = sample.get('adv', '').strip()
        
        # Logic ki·ªÉm tra success
        if gold_out == '':
            expected_success = 3  # Empty Gold
        elif change == 0:
            expected_success = 2  # No Changes
        elif after_attack_bleu < pred_bleu:
            expected_success = 1  # Attack Success
        else:
            expected_success = 4  # Attack Failed
            
        if success != expected_success:
            sample_issues.append({
                'type': 'success_logic_error',
                'description': f'Success logic error: expected {expected_success}, got {success}',
                'details': {
                    'pred_bleu': pred_bleu,
                    'after_bleu': after_attack_bleu,
                    'change': change,
                    'gold_empty': gold_out == '',
                    'bleu_decreased': after_attack_bleu < pred_bleu
                }
            })
        
        # 2. Ki·ªÉm tra t√≠nh nh·∫•t qu√°n c·ªßa changes
        if change != len(changes):
            sample_issues.append({
                'type': 'change_count_mismatch',
                'description': f'Change count mismatch: change={change}, len(changes)={len(changes)}',
                'details': {
                    'change_field': change,
                    'changes_length': len(changes),
                    'changes_content': changes
                }
            })
        
        # 3. Ki·ªÉm tra logic c·ªßa query
        if change > 0 and query == 0:
            sample_issues.append({
                'type': 'query_logic_error',
                'description': f'Query should not be 0 when changes exist',
                'details': {
                    'change': change,
                    'query': query,
                    'changes': changes
                }
            })
        
        # 4. Ki·ªÉm tra input v√† adv consistency
        if change > 0 and input_text == adv_text:
            sample_issues.append({
                'type': 'input_adv_consistency',
                'description': f'Adv should be different from input when changes exist',
                'details': {
                    'input': input_text,
                    'adv': adv_text,
                    'changes': changes
                }
            })
        
        # 5. Ki·ªÉm tra imp_words
        imp_words = sample.get('imp_words', {})
        if change > 0 and not imp_words:
            sample_issues.append({
                'type': 'imp_words_missing',
                'description': f'Imp_words should not be empty when changes exist',
                'details': {
                    'change': change,
                    'imp_words': imp_words,
                    'changes': changes
                }
            })
        
        # 6. Ki·ªÉm tra BLEU scores validity
        if pred_bleu < 0 or pred_bleu > 100:
            sample_issues.append({
                'type': 'invalid_bleu_score',
                'description': f'Invalid pred_bleu: {pred_bleu}',
                'details': {'pred_bleu': pred_bleu}
            })
        
        if after_attack_bleu < 0 or after_attack_bleu > 100:
            sample_issues.append({
                'type': 'invalid_bleu_score',
                'description': f'Invalid after_attack_bleu: {after_attack_bleu}',
                'details': {'after_bleu': after_attack_bleu}
            })
        
        # 7. Ki·ªÉm tra data quality
        if not input_text and change > 0:
            sample_issues.append({
                'type': 'data_quality',
                'description': f'Empty input but has changes',
                'details': {
                    'input': input_text,
                    'change': change,
                    'changes': changes
                }
            })
        
        if sample_issues:
            analysis['logic_issues'].append({
                'sample_index': i,
                'issues': sample_issues,
                'sample_data': {
                    'success': success,
                    'pred_bleu': pred_bleu,
                    'after_bleu': after_attack_bleu,
                    'change': change,
                    'query': query,
                    'input': input_text,
                    'adv': adv_text,
                    'gold_out': gold_out
                }
            })
    
    # Ph√¢n lo·∫°i l·ªói
    error_types = {}
    for issue in analysis['logic_issues']:
        for problem in issue['issues']:
            error_type = problem['type']
            if error_type not in error_types:
                error_types[error_type] = []
            error_types[error_type].append(problem['description'])
    
    analysis['error_summary'] = error_types
    
    # ƒê∆∞a ra khuy·∫øn ngh·ªã
    recommendations = []
    
    if 'success_logic_error' in error_types:
        recommendations.append({
            'issue': 'Logic l·ªói trong field success',
            'count': len(error_types['success_logic_error']),
            'solution': 'C·∫ßn s·ª≠a l·∫°i logic x√°c ƒë·ªãnh success trong code attack'
        })
    
    if 'change_count_mismatch' in error_types:
        recommendations.append({
            'issue': 'S·ªë l∆∞·ª£ng change kh√¥ng kh·ªõp v·ªõi changes array',
            'count': len(error_types['change_count_mismatch']),
            'solution': 'C·∫ßn ƒë·ªìng b·ªô h√≥a vi·ªác ƒë·∫øm changes v√† c·∫≠p nh·∫≠t field change'
        })
    
    if 'query_logic_error' in error_types:
        recommendations.append({
            'issue': 'Query = 0 khi c√≥ changes',
            'count': len(error_types['query_logic_error']),
            'solution': 'C·∫ßn ƒë·∫£m b·∫£o query > 0 khi c√≥ thay ƒë·ªïi ƒë∆∞·ª£c th·ª±c hi·ªán'
        })
    
    if 'input_adv_consistency' in error_types:
        recommendations.append({
            'issue': 'Input v√† adv gi·ªëng nhau khi c√≥ changes',
            'count': len(error_types['input_adv_consistency']),
            'solution': 'C·∫ßn ki·ªÉm tra logic t·∫°o adversarial example'
        })
    
    analysis['recommendations'] = recommendations
    
    return analysis

def print_detailed_report(analysis: Dict[str, Any]):
    """In b√°o c√°o chi ti·∫øt"""
    print("=" * 80)
    print("PH√ÇN T√çCH CHI TI·∫æT L·ªñI LOGIC TRONG K·∫æT QU·∫¢ JSON")
    print("=" * 80)
    
    print(f"\nüìä T·ªîNG QUAN:")
    print(f"   - T·ªïng s·ªë samples: {analysis['total_samples']}")
    print(f"   - S·ªë samples c√≥ l·ªói: {len(analysis['logic_issues'])}")
    print(f"   - T·ª∑ l·ªá l·ªói: {(len(analysis['logic_issues']) / analysis['total_samples']) * 100:.1f}%")
    
    print(f"\nüîç PH√ÇN LO·∫†I L·ªñI:")
    for error_type, errors in analysis['error_summary'].items():
        print(f"   - {error_type}: {len(errors)} l·ªói")
        # Hi·ªÉn th·ªã 3 v√≠ d·ª• ƒë·∫ßu ti√™n
        for i, error in enumerate(errors[:3]):
            print(f"     {i+1}. {error}")
        if len(errors) > 3:
            print(f"     ... v√† {len(errors) - 3} l·ªói kh√°c")
    
    print(f"\nüí° KHUY·∫æN NGH·ªä KH·∫ÆC PH·ª§C:")
    for rec in analysis['recommendations']:
        print(f"   - {rec['issue']} ({rec['count']} l·ªói)")
        print(f"     Gi·∫£i ph√°p: {rec['solution']}")
    
    # Hi·ªÉn th·ªã m·ªôt s·ªë v√≠ d·ª• c·ª• th·ªÉ
    print(f"\nüìã V√ç D·ª§ L·ªñI C·ª§ TH·ªÇ:")
    for i, issue in enumerate(analysis['logic_issues'][:5]):
        print(f"\n   Sample {issue['sample_index']}:")
        sample_data = issue['sample_data']
        print(f"     Success: {sample_data['success']}")
        print(f"     Pred BLEU: {sample_data['pred_bleu']:.2f}")
        print(f"     After BLEU: {sample_data['after_bleu']:.2f}")
        print(f"     Change: {sample_data['change']}")
        print(f"     Query: {sample_data['query']}")
        print(f"     Input: '{sample_data['input']}'")
        print(f"     Adv: '{sample_data['adv']}'")
        print(f"     Gold: '{sample_data['gold_out']}'")
        
        for problem in issue['issues']:
            print(f"     ‚ùå {problem['description']}")

def main():
    """Main function"""
    file_path = "output/translation/codet5/codebert/cs_java_test_run/66.json"
    
    if not os.path.exists(file_path):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {file_path}")
        return
    
    print("üîç ƒêang ph√¢n t√≠ch chi ti·∫øt file k·∫øt qu·∫£...")
    analysis = detailed_logic_analysis(file_path)
    print_detailed_report(analysis)
    
    # L∆∞u b√°o c√°o chi ti·∫øt
    report_file = "detailed_analysis_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, indent=2, ensure_ascii=False)
    print(f"\nüíæ B√°o c√°o chi ti·∫øt ƒë√£ l∆∞u v√†o: {report_file}")

if __name__ == "__main__":
    main() 